# Streamlining Data Pipelines in Databricks with dbx: Combining Notebooks, Python Scripts, and Workflows for Scalable Production-Ready Solutions
For instructions, please go to the medium article: [Medium Article](https://medium.com/d-one/how-to-streamline-data-pipelines-in-databricks-with-dbx-7c92e8ab1d2es)

----------------------------------------------------------------------------------------------

# Prerequisite
* Connect to Unity Catalog
* 

<!-- 
# For Remote Testing
```
python -m venv venvr
source venvr/bin/activate
pip install -e .[remote]
```

Install the vscode databricks extension and follow the instructions:
1. Click on the Databricks Icon in the left panel
2. Click on `Configure Databricks`
3. Either choose the existing cluster that you configured in the previous article OR choose another one.
  * If you choose to add another one, you have to option to authenticate through Azure CLI (If you are using Databricks on Azure)
4. Click on Clusters to the left and choose your own Cluster or Create a new one
  * A single node cluster is enough for this exercise.
5. Start the Cluster by clicking on the green arrow  
 -->